{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a2e7334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import numpy as np\n",
    "# If these have already been installed, this cell can be commented out.\n",
    "#!pip install tensorflow_probability==0.14.0\n",
    "#!pip install pennylane-lightning[gpu]\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import pearsonr   \n",
    "import tensorflow_probability as tfp\n",
    "from __future__ import print_function\n",
    "print(__doc__)\n",
    "\n",
    "#!pip install -U scikit-learn scipy matplotlib\n",
    "#!pip install grakel\n",
    "#import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from grakel.datasets import fetch_dataset\n",
    "from grakel.kernels import ShortestPath\n",
    "from time import time\n",
    "from functools import partial\n",
    "import cirq, sympy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2446301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reindex_nodes_and_edges(node_sub, edge_sub):\n",
    "    # Create a dictionary to map old node indices to new node indices\n",
    "    node_map = {old_index: new_index for new_index, old_index in enumerate(node_sub)}\n",
    "\n",
    "    # Create new node indices\n",
    "    new_node_sub = list(range(len(node_sub)))\n",
    "\n",
    "    # Create new edge indices using the node mapping\n",
    "    new_edge_sub = [[node_map[edge[0]], node_map[edge[1]]] for edge in edge_sub]\n",
    "\n",
    "    return new_node_sub, new_edge_sub\n",
    "def nodembedding(node_array, edge_array, node_features_array):\n",
    "  \n",
    "    V = len(node_array)\n",
    "    subgraphs = {}\n",
    "    for node_index in range(V):\n",
    "        # create a subgraph containing the current node and its neighbors\n",
    "        subgraph_nodes = [node_array[node_index]]\n",
    "        subgraph_edges = [edge for edge in edge_array if node_array[node_index] in edge]\n",
    "        for edge in subgraph_edges:\n",
    "            neighbor_index = 1 if edge[0] == node_array[node_index] else 0\n",
    "            neighbor = edge[neighbor_index]\n",
    "            if neighbor not in subgraph_nodes:\n",
    "                # find the index of the neighbor in node_array and add it to the subgraph_nodes list\n",
    "                neighbor_index = np.where(node_array == neighbor)[0][0]\n",
    "                subgraph_nodes.append(node_array[neighbor_index])\n",
    "        \n",
    "        # extract the features for the nodes in the subgraph\n",
    "        sub_features = node_features_array[np.isin(node_array, subgraph_nodes)]\n",
    "        \n",
    "        subgraph_nodes=np.sort(np.array(subgraph_nodes))\n",
    "        subgraph_edges=np.array(subgraph_edges)\n",
    "        shift = np.unique(subgraph_edges.flatten())\n",
    "        shift=shift.min()\n",
    "        subgraph_nodes -=shift\n",
    "        subgraph_edges -=shift\n",
    "        subgraph_nodes,subgraph_edges= reindex_nodes_and_edges(subgraph_nodes,subgraph_edges)\n",
    "        \n",
    "        subgraph = (subgraph_nodes,subgraph_edges )\n",
    "\n",
    "        # add the subgraph and sub-features to the dictionary\n",
    "        subgraphs[node_index] = {'subgraph': subgraph, 'sub_features': sub_features}\n",
    "    \n",
    "    return subgraphs\n",
    "\n",
    "def graph_to_arrays(G):\n",
    "    edges = np.array(list(G[0]), dtype=int)\n",
    "    nodes = np.unique(edges.flatten())\n",
    "    node_labels = np.array([G[1][node] for node in nodes], dtype=int)\n",
    "    edge_labels = np.array([G[2][tuple(edge)] for edge in edges], dtype=int)\n",
    "    shift=nodes.min()\n",
    "    nodes -= shift # Shift nodes so that they start at 0\n",
    "    edges -= shift # Shift edges so that they start at 0\n",
    "\n",
    "    return nodes, edges, node_labels, edge_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3995e042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossmapping(params,nodes,node_feat):\n",
    "    loss = 0\n",
    "    V = len(nodes)\n",
    "    if ((params.shape[0]) - len(node_feat[0])) ** 2 > 0:\n",
    "        print(\"The number of parameters and the feature size do not coincide\")    \n",
    "    D = tfp.stats.correlation(node_feat, node_feat,sample_axis=1, event_axis=0)  # Compute the correlation using tfp.stats.correlation\n",
    "        \n",
    "    state_vectors = []\n",
    "    dev = qml.device(\"default.qubit\", wires=1)\n",
    "    @qml.qnode(dev, interface=\"tf\",diff_method=\"backprop\")\n",
    "    def circuitdummy(node,params):\n",
    "        for i in range(params.shape[0]):\n",
    "            qml.RX(params[i]*node_feat[node][i], wires=[0])\n",
    "           \n",
    "        return qml.state()\n",
    "    \n",
    "    for index in range(V):\n",
    "        value = (circuitdummy(index,params))\n",
    "        state_vectors.append(value)\n",
    "    \n",
    "    D_vec = tf.Variable(tf.zeros([V, V], dtype=tf.float64))# Define a TensorFlow variable to store the computed distance matrix\n",
    "    for i in range(V):\n",
    "        for j in range(0, i):\n",
    "            innprod = tf.linalg.adjoint(tf.reshape(state_vectors[i], (2, 1))) @ tf.reshape(state_vectors[j], (2, 1))\n",
    "            corr_val = tf.math.abs(tf.math.real(innprod))\n",
    "            ij = tf.math.acos(corr_val)*2/np.pi\n",
    "            updates = tf.squeeze(tf.stack([ij, ij]))\n",
    "            D_vec = tf.tensor_scatter_nd_update(D_vec, [[i, j], [j, i]], updates)\n",
    "    for i in range(V):\n",
    "        for j in range(0, i):\n",
    "            loss -= tf.math.abs(D[i][j] - D_vec[i][j])\n",
    "    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8233c8-1751-4aac-a394-cc429b9a8dca",
   "metadata": {},
   "source": [
    "We do not need the following code for the dataset mutag because the node labels are from 1 to 17, but in general it can be used to encode node attributes\n",
    "in such a way that the corresponding circuit represent them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1c7cea-1bd3-4697-bf54-803ce237eba4",
   "metadata": {
    "tags": []
   },
   "source": [
    "parameters =np.array(np.random.normal(scale=0.3, size=(len(node_features[0]),)))\n",
    "print(parameters)\n",
    "params=tf.Variable(parameters,dtype=tf.float64)# Run the optimization\n",
    "#--- Define the optimizer\n",
    "print(\"params\",params)\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.03)\n",
    "cost =lambda: lossmapping(params,node_list,node_features)\n",
    "\n",
    "steps = 200\n",
    "\n",
    "for i in range(steps):\n",
    "    #print(i)\n",
    "    \n",
    "    #print(\"PARAMS\",params,type(params))\n",
    "    #print(i)\n",
    "    opt.minimize(cost, params)\n",
    "    #print(\"last line\",params,opt.minimize(cost, params),type(opt.minimize(cost, params)) )\n",
    "    #print(opt.minimize(cost, params),type(opt.minimize(cost, params)))\n",
    "    #print()\n",
    "    if i%50==0:\n",
    "        print(\"COST func\",cost(),type(cost),\"step\",i)\n",
    "\n",
    "        energy = lossmapping(params,node_list,node_features)\n",
    "        print(\"Ground state energy: \", energy)\n",
    "        \n",
    "#--- Compute the final energy\n",
    "energy = lossmapping(params,node_list,node_features)\n",
    "print(\"Ground state energy: \", energy)\n",
    "print(params)\n",
    "print(node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4f2b565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Collecting grakel\n",
      "  Downloading GraKeL-0.1.9-cp38-cp38-win_amd64.whl (665 kB)\n",
      "     -------------------------------------- 665.5/665.5 kB 8.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\lavoro\\anaconda3\\lib\\site-packages (from grakel) (1.16.0)\n",
      "Requirement already satisfied: cython>=0.27.3 in c:\\users\\lavoro\\anaconda3\\lib\\site-packages (from grakel) (0.29.33)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\lavoro\\anaconda3\\lib\\site-packages (from grakel) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn>=0.19 in c:\\users\\lavoro\\anaconda3\\lib\\site-packages (from grakel) (1.2.1)\n",
      "Requirement already satisfied: future>=0.16.0 in c:\\users\\lavoro\\anaconda3\\lib\\site-packages (from grakel) (0.18.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\lavoro\\anaconda3\\lib\\site-packages (from grakel) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lavoro\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19->grakel) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\lavoro\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19->grakel) (1.10.0)\n",
      "Installing collected packages: grakel\n",
      "Successfully installed grakel-0.1.9\n"
     ]
    }
   ],
   "source": [
    "# Loads the MUTAG dataset\n",
    "PTC_FM = fetch_dataset(\"PTC_FM\", verbose=False)\n",
    "G, y = PTC_FM.data, PTC_FM.target\n",
    "#print(PTC_FM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ad39e0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "[2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 3] <class 'numpy.ndarray'> 16\n"
     ]
    }
   ],
   "source": [
    "max_nodes=0\n",
    "pos=0\n",
    "for i in range(len(y)):\n",
    "    if len(G[i][1].keys())>max_nodes:\n",
    "        max_nodes=len(G[i][1].keys())\n",
    "        pos=i\n",
    "print(max_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52cb0791-6851-485f-a30f-6dd8649e084a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "max_subgraphlength=0\n",
    "for i in range(len(y)):\n",
    "    graph_car=graph_to_arrays(G[i])\n",
    "    node_list=graph_car[0]\n",
    "    edge_list=graph_car[1]\n",
    "    node_features= graph_car[2]\n",
    "    subgraphs=nodembedding(node_list, edge_list, node_features)\n",
    "    for index in subgraphs:\n",
    "        #print(index, subgraphs[index][\"subgraph\"][0])\n",
    "        if len(subgraphs[index][\"subgraph\"][0])>max_subgraphlength:\n",
    "            max_subgraphlength=len(subgraphs[index][\"subgraph\"][0])\n",
    "print(max_subgraphlength)\n",
    "wirestot=max_subgraphlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c67090f2-691c-462d-9c05-5a69ff03a939",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def circuitfinalansatz(param_fixed,var_par, graph_node_list, graph_edges_list, graph_node_feat):\n",
    "    ####Preparation of the circuit according to the encoding of the node features\n",
    "    ###Inputs: param_fixed are the initialization parameters to encode the information in the nodes\n",
    "    ###\"\"    : var_par are the variational parameters for the classification problem\n",
    "    V=len(graph_node_list)\n",
    "    for node in range(V):\n",
    "        \n",
    "        #for our dataset graph_node_feat is just a single number, in general unccoment those lines>:\n",
    "        #for i in range(graph_node_feat.shape[1]):\n",
    "\n",
    "                #qml.RX(param_fixed[i]*graph_node_feat[node][i], wires=[node])\n",
    "        for i in range(1):\n",
    "\n",
    "                qml.RX(param_fixed*graph_node_feat[node], wires=[node])       \n",
    "    for qubit in range(V):\n",
    "        qml.RZ(var_par[3*qubit], wires=qubit)\n",
    "        qml.RY(var_par[3*qubit+1], wires=qubit)\n",
    "        qml.RZ(var_par[3*qubit+2], wires=qubit)\n",
    "    for edge in graph_edges_list:\n",
    "        #Here we can insert the edge label encoded as a number, and also account for node features as (x_i -x_j)*edge_ij as rot angle to extend the expressivity of the model\n",
    "        #For the simple case hereby considered we don't do that\n",
    "        qml.IsingZZ(phi=var_par[3*V],wires=[edge[0],edge[1]])\n",
    "    for qubit in range(wirestot): \n",
    "        qml.CNOT(wires=[qubit, (qubit+1)%(wirestot+1)])\n",
    "    for qubit in range(V):\n",
    "        qml.RZ(var_par[3*V+3*qubit], wires=qubit)\n",
    "        qml.RY(var_par[3*V+3*qubit+1], wires=qubit)\n",
    "        qml.RZ(var_par[3*V+3*qubit+2], wires=qubit)    \n",
    "  \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77d04b9d-cae1-4593-bf56-cd574b33f3ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "332\n"
     ]
    }
   ],
   "source": [
    "G_train, G_test, y_train, y_test = train_test_split(G, y, test_size=0.95, random_state=42)\n",
    "\n",
    "print(len(y_train))\n",
    "print(len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88b3bc8-ef13-4cf2-8fe8-70c75de88d85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entering the for loop; 0\n",
      "COST func tf.Tensor(-16.757490687082612, shape=(), dtype=float64) <class 'function'> step 0\n",
      "entering the for loop; 1\n",
      "COST func tf.Tensor(-16.799979650887593, shape=(), dtype=float64) <class 'function'> step 1\n",
      "entering the for loop; 2\n",
      "COST func tf.Tensor(-16.769034085042716, shape=(), dtype=float64) <class 'function'> step 2\n",
      "entering the for loop; 3\n",
      "COST func tf.Tensor(-17.136503211237986, shape=(), dtype=float64) <class 'function'> step 3\n",
      "entering the for loop; 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "var_param=np.array(np.random.normal(scale=0.3, size=(6*max_subgraphlength+1,)))\n",
    "params= tf.Variable(var_param,dtype=tf.float64)\n",
    "params_init=tf.Variable(2*np.pi/17)\n",
    "def traincost(params):\n",
    "    vn_entropies=list()\n",
    "    loss=0\n",
    "    state_vectors = []\n",
    "    cost_vec=[]\n",
    "    dev=qml.device('default.qubit', wires=max_subgraphlength+1)\n",
    "    @qml.qnode(dev, interface=\"tf\",diff_method=\"backprop\")\n",
    "    def finalcost(subgraphs,params_init,var_param,node_list):\n",
    "        for node in range(len(node_list)):\n",
    "            subgraph=subgraphs[node][\"subgraph\"]\n",
    "            sub_node, sub_edge= subgraphs[node][\"subgraph\"]\n",
    "            sub_feat=subgraphs[node][\"sub_features\"]\n",
    "            #wires_array = np.arange(wires)\n",
    "            #print(wires_array)\n",
    "            circuitfinalansatz(params_init,params, sub_node, sub_edge, sub_feat)  \n",
    "        return qml.expval(qml.PauliZ(max_subgraphlength))\n",
    "\n",
    "    for i in range(len(y_train)):\n",
    "    \n",
    "        graph_car=graph_to_arrays(G_train[i])\n",
    "        node_list=graph_car[0]\n",
    "        edge_list=graph_car[1]\n",
    "        node_features= graph_car[2]\n",
    "        subgraphs=nodembedding(node_list, edge_list, node_features)\n",
    "        value=0\n",
    "        \n",
    "        value=(finalcost(subgraphs,params_init,var_param,node_list))\n",
    "        \n",
    "        state_vectors.append(value)\n",
    "\n",
    "    for i in range(len(y_train)):\n",
    "        cost_vec.append(-tf.math.abs(state_vectors[i]+y_train[i]))\n",
    "    loss=tf.reduce_sum(cost_vec)\n",
    "    return loss\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.03)\n",
    "    \n",
    "cost =lambda: traincost(params)\n",
    "\n",
    "steps = 200\n",
    "for i in range(steps):\n",
    "    print(\"entering the for loop:\",i)\n",
    "    \n",
    "    \n",
    "    opt.minimize(cost, params)\n",
    "    \n",
    "    print(\"COST func\",cost(),type(cost),\"step\",i)\n",
    "\n",
    "  \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddef310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bbd6f7-425a-4efe-a1eb-b5f2b29f45cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa984430-0efe-48a4-bd94-44da06b88c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bec231e-cc37-4f3d-a46c-aa67dab86aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5ebd64-8c70-463d-acd2-ff842429fff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc643edd-8df7-46cc-a1ca-9114d9f81a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff17f16-f7bf-48f6-bfb0-4288ceb3950d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279bef12-9dbe-4b85-8dbd-4b87cb2b1109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469c7b8b-dfa8-4318-939d-66c112f058aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
